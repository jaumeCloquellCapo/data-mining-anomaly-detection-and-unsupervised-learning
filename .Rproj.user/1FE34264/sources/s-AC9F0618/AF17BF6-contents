---
title: "Ripper"
author: "Juan Antonio Cortés Ibáñez"
date: "28 January 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(DMwR)
library(NoiseFiltersR)
library(Boruta)
library(caret)
library(RWeka)
library(kknn)
library(outliers)
library(extremevalues)
library(missForest)
library(dplyr)
```

## Ripper

Lectura de datos:
```{r}
data_train <- read.csv("../datasets/proccesed/ripper/my_dataset_train.csv")
data_test <- read.csv("../datasets/proccesed/ripper/my_dataset_test.csv")
#data_test <- as.data.frame(scale(data_test))
#data_test <- knnImputation(data_test, k=3)
```
Fusión para normalizar e imputar con todo:
```{r}
# Read CSVs and store the class column,
data_train_bak <- read.csv("../datasets/proccesed/ripper/my_dataset_train.csv")
data_train_bak_class <- data_train_bak$y
data_test_bak <- read.csv("../datasets/proccesed/ripper/my_dataset_test.csv")
# Merge both of the datasets
data_merged <- rbind(data_train_bak[1:ncol(data_train_bak)-1], data_test_bak)
# Scaling and imputation
data_merged <- as.data.frame(scale(data_merged))
data_merged <- knnImputation(data_merged, k=3)
# Recreating the train and test datasets
data_train_bak <- data_merged[1:2728,]
data_train_bak$y <- data_train_bak_class
data_test_bak <- data_merged[2729:3411,]
```

Uniendo ejemplos nuevos seguros:

```{r}
knn_classes <- read.csv("1nn_classes.csv")
rnn_classes <- read.csv("rn_classes.csv")
common_classes <- inner_join(knn_classes, rnn_classes)
new_train_examples <- data_test_bak[common_classes$Id,]
new_train_examples$y <- common_classes$prediction
data_train_bak <- rbind(data_train_bak, new_train_examples)
```


Imputando valores perdidos:
```{r}
missing_values <- function(data_train, k_value) {
  data_1 <- data_train[,1:ncol(data_train)-1]
  data_1$y <- data_train$y
  data_2 <- knnImputation(data_1, k=k_value)
  return(data_2)
}
```

Limpiando ruido:
```{r}
noise_filter <- function(data_train){
  data_train$y <- as.factor(data_train$y)
  data_train <- IPF(data_train, consensus = TRUE)$cleanData
  return(data_train)
}
```

Selección de características:
```{r}
feature_selection <- function(data_train){
  boruta.train <- Boruta(y ~ ., data = data_train, doTrace = 2)
  selectedAttributes <- getSelectedAttributes(boruta.train)
  data_1 <- data_train[ , selectedAttributes]
  data_1$y <- data_train$y
  return(data_1)
}
```

Validación cruzada:
```{r}
cross_validation <- function(dataset){
  partition <- createDataPartition(dataset$y, p=0.8, list=FALSE)  
  train_data <- dataset[partition,]
  test_data <- dataset[-partition,]
  train_model <- JRip(y ~ ., train_data)
  
  predicted_result <- evaluate_Weka_classifier(train_model,test_data, numFolds = 5)
  print(predicted_result)
  return(train_model)
}
```

Valores anómalos:
```{r}
na_outliers <- function(dataset){
  for (col in colnames(dataset)) {
    outliers <- getOutliers(dataset[,col], method="I",distribution="normal")
    if(length(outliers$iLeft) > 0){
      for (outlier in outliers$iLeft) {
        dataset[outlier, which(colnames(dataset)==col)] <- NA
      }
    }
    if(length(outliers$iRight) > 0){
      for (outlier in outliers$iRight) {
        dataset[outlier, which(colnames(dataset)==col)] <- NA
      }
    }
  }
  return (dataset)
}
```


Experimentos:
```{r eval=FALSE, include=FALSE}
data_train <- data_train_bak
data_test <- data_test_bak
data_train$x14 <- NULL
data_train$x51 <- NULL
data_train$x63 <- NULL
data_train$x41 <- NULL

data_2 <- missing_values(data_train, 3)
data_3 <- noise_filter(data_2)
data_4 <- feature_selection(data_3)
data_5 <- SMOTE(y ~ ., data_4, perc.over = 500, perc.under=600)
data_6 <- ENN(data_5, k = 3)$cleanData
predicted_result <-kknn(y ~ ., data_6, data_test, k=1, kernel = "gaussian")
write.csv(predicted_result$fitted.values, "../results/ripper/predicted_data_new.csv")
```