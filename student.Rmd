---
title: "Untitled"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(grid) 
library(gridExtra)
library(tidyverse)
library(dummies)
library(readxl)
library(knitr)
library(ggplot2)
library(lubridate)
library(arules)
library(arulesViz)
library(plyr)
library(corrplot)
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción al dataset

Para la práctica de reglas de asociación de la asignatura *"Minería de Datos: Detección de Anomálias y  Aprendizaje no Supervisado"* se ha utilizado un dataset recuperado de la web de UCI. El objetivo des predecir la nota final G3 de un conjunto de datos de alumnos dado. 

Para ello generaramos dos modelos machine learning a partir de un análisis descriptivo y exploratorio utilizando un metodo no supervisado. Los datos los obtenemos en https://archive.ics.uci.edu/ml/datasets/Student+Performance.

Vamos a trabajar únicamente con el dataset de la asignatura de portugués
```{r}
studentMat <- read.table("student/student-mat.csv", row.names=NULL, sep=";", header=TRUE)
studentPor <- read.table("student/student-por.csv", row.names=NULL, sep=";", header=TRUE)
```

# Análisis exploratorio

Vamos a comprobar si tenemos datos completos en los datos, ya que los valores perdidos siempre pueden causar problemas. 

```{r, echo=FALSE}
any(is.na(studentPor))
```

Vemos que no hay valores perdidos por lo que el siguiente paso será ver de que tipo son nuestros datos, así como sus distribuciones para comenzar a hacernos una idea de que es lo que tenemos entre manos. Parece que tenemos una combinación entre factores y variables numéricas.

```{r, echo=FALSE}
str(studentPor)
# table(sapply(studentPor, class))
```

Vemos que tenemos 33, 17 factores que trataremos a continuación y el resto poseen valores enteros. De las 16 variables de tipo enteros, todas ellas son variables categóricas que trataremos más adelante. Los datos de nuestro dataset son extremadamente compatibles con el análisi, ya que la mayoría de las columnas son variables binarias o elementos de un conjunto finito de valor discreto cuyo tamaño oscila alrededor de 5. Por lo tanto, podemos cambiar la clase de la mayoría de Las columnas a factorizar.

# Limpieza de datos

Al igual que solo necesitamos una columna G1 modificada para evaluar el rendimiento, hay varias columnas en el conjunto de datos que no mejoran nuestra comprensión de la situación. Las tres variables de grado (G1 y G2) indican el elemento que queremos predecir, por lo que nos deshacemos de ellas. Además, no necesitamos hacer ninguna distinción entre las dos escuelas y podemos resumir Dalc y Walc como una única variable (alcohol)

```{r, echo=FALSE}
names(studentPor) <- tolower(names(studentPor)) # para simplicar las variable, todas las variables poseen el nombre en minúscula.
studentPor.original <- studentPor #hacemos una copia para guardar los valores originales
```


```{r, echo=FALSE}
studentPor$pass <- ifelse(studentPor$g3 > 9, 1, 0) #variable a predecir
studentPor$g2 <- NULL
studentPor$g1 <- NULL
studentPor$school <- NULL
#studentPor$address <- NULL
studentPor$g3 <- NULL
studentPor$alcohol <- ifelse(((studentPor$dalc * 5 + studentPor$walc * 2) / 7) < 3, 0, 1)
#studentPor$walc <- NULL
#studentPor$dalc <- NULL
```

# Análisis exploratorio

Empecemos con una exploración de datos usando nada más que nuestra intuición. Si creemos en la sabiduría convencional, debería existir una alta correlación positiva entre la variable de tiempo de estudio con la nota final del alumno.
Además el estado de la educación de los padres se cita habitualmente como un importante predictor del éxito académico de los estudiantes en muchas publicaciones de analítica de estudiantes

Para ver lo correladas que están unas variables con otras, y también con Pass, podemos calcular y dibujar una matriz de correlación. Primero creamos variables dummies para las variables de tipo factor que queramos incluir en la matriz de correlación. 

```{r, echo=FALSE}
studentPor.factor <- studentPor
studentPor.factor$age <- cut(studentPor$age, breaks = c(14, 18, 22))
studentPor.factor$medu <- as.factor(studentPor$medu)
studentPor.factor$fedu <- as.factor(studentPor$fedu)
studentPor.factor$studytime <- as.factor(studentPor$studytime)
studentPor.factor$traveltime <- as.factor(studentPor$traveltime)
studentPor.factor$failures <- as.factor(studentPor$failures)

studentPor.factor$famrel <- as.factor(studentPor$famrel)
studentPor.factor$freetime <- as.factor(studentPor$freetime)
studentPor.factor$goout <- as.factor(studentPor$goout)
studentPor.factor$walc <- as.factor(studentPor$walc)
studentPor.factor$dalc <- as.factor(studentPor$dalc)
studentPor.factor$health <- as.factor(studentPor$health)
studentPor.factor$absences <- as.factor(studentPor$absences)

#studentPor.factor$g3 <- as.factor(ifelse(studentPor$g3 > 9, 1, 0))
#studentPor.factor$g2 <- as.factor(ifelse(studentPor$g2 > 9, 1, 0))
#studentPor.factor$g1 <- as.factor(ifelse(studentPor$g1 > 9, 1, 0))
```

```{r, echo=FALSE}
studentPor.numeric <- studentPor
studentPor.numeric$pstatus <- as.numeric(studentPor$pstatus)
studentPor.numeric$sex <- as.numeric(studentPor$sex)
studentPor.numeric$famsize <- as.numeric(studentPor$famsize)
studentPor.numeric$address <- as.numeric(studentPor$address)
studentPor.numeric$schoolsup <- as.numeric(studentPor$schoolsup) - 1
studentPor.numeric$famsup <- as.numeric(studentPor$famsup) - 1
studentPor.numeric$paid <- as.numeric(studentPor$paid) - 1
studentPor.numeric$activities <- as.numeric(studentPor$activities) - 1
studentPor.numeric$higher <- as.numeric(studentPor$higher) - 1
studentPor.numeric$internet <- as.numeric(studentPor$internet) - 1
studentPor.numeric$romantic <- as.numeric(studentPor$romantic) - 1
studentPor.numeric$nursery <- as.numeric(studentPor$nursery) - 1
studentPor.numeric$reason <- as.numeric(studentPor$reason)
studentPor.numeric$guardian <- as.numeric(studentPor$guardian)
studentPor.numeric$fjob <- as.numeric(studentPor$fjob)
studentPor.numeric$mjob <- as.numeric(studentPor$mjob)
studentPor.numeric <- as.data.frame(studentPor.numeric)
```


```{r, echo=FALSE}
icorrplot <- function (dataset) {
  cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
      for (j in (i + 1):n) {
        tmp <- cor.test(mat[, i], mat[, j], ...)
        p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
      }
    }
    colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
    p.mat
  }
  # matrix of the p-value of the correlation
  p.mat <- cor.mtest(dataset)
  col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
  M <- cor(dataset)
  cex.before <- par("cex")
  par(cex = 0.1)
 corrplot(M, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "grey", # Add coefficient of correlation
         tl.cex = 1/par("cex"),
         cl.cex = 1/par("cex"),
         tl.col="black", 
         tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, 
         sig.level = 0.01,
         addCoefasPercent = TRUE,
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
)
  par(cex = cex.before)
}
```

```{r, echo=FALSE}
icorrplot(studentPor.numeric)
```

Aqui ya podemos ver de un simple vistazo que variable poseen un alto nivel de correlación y por tanto serán con las que trabjaremos en los siguientes análisis.

*Podemos ver que las relaciones son bastante leves
*Los alumnos con más failures tienen una nota más baja.
*La edad influye de forma negativa en la nota de los estudiantes.
*Los alumnos con más tiempo de estudio tienen una nota más alta.
*Aquellos que quieren ir a la universidad tienen una nota más alta (higher).
*Se parecia una correlación fuerte del arpobado y el nivel educativo de los padres

## Nivel educativo de los padres

El nivel educativo de los padres tiene un alto nivel de correlación. Vamos a profundizar en el análisis de la distribución de datos.

El trabajo de la madre se agrupa en cinco categorías: ama de casa, sectores de empleo (salud, educación, otros servicios) y otros. La clasificación en salud y educación es realmente importante ya que estos dos son sumamente cruciales en la educación de un niño y una madre que trabaja en estos campos podría ayudar al niño aún más.Además, la distinción de ama de casa, empleada y otra también es importante porque las madres que hacen tareas domésticas a tiempo completo podrían enfocarse más en las necesidades de sus hijos. Todas estas hiposias deben ser probadas para veracidad.

Ahora comparemos el trabajo de la madre y el grado de los estudiantes.

```{r, echo=FALSE}
ggplot(data = studentPor, aes(mjob)) +
  facet_wrap(~ pass) +
  geom_histogram(bins = 12, stat = "count", fill="dodgerblue1") +
  ggtitle("Distribution of mjob Education in student data") +
  xlab("mjob") +
  ylab("Distribution of Higher Education")+
  theme(plot.title=element_text(face="bold"))
```

Sería conveniente una clasificación más detallada de las profesiones de las madres de los alumnos. Puede guardar alguna relación con la nota final, seguramente en combinación con otras variables, pero hay muchas instancias de “Other”. Los hijos de madres que son amas de casa tienen más probabilidades de tener un desempeño inferior al promedio que otros niños. Mientras tanto, es más probable que los niños cuyas madres trabajan en el sector de la salud tengan un desempeño superior al promedio.

## Educación Superior

Pasemos a la distribución de la educación superior. Esta variable representa la disposición de los estudiantes para continuar su educación superior.  Está bastante sesgado como se esperaba. Muchos estudiantes han respondido que sí. Es posible que tengamos que igualar la distribución antes de determinar si esto proporciona información significativa sobre las calificaciones.

```{r, echo=FALSE}
ggplot(data = studentPor, aes(higher)) +
  facet_wrap(~ pass) +
  geom_histogram(bins = 12, stat = "count", fill="dodgerblue1") +
  ggtitle("Distribution of Higher Education in student data") +
  xlab("Higher Education") +
  ylab("Distribution of Higher Education")+
  theme(plot.title=element_text(face="bold"))
```

## Dedicación al estudio

Como es lógico la dedicación al estudio influye con el aprobado y el suspendo. Esta variable, al no poseer información relevante, la descartaremos para así evitar que se generen reglas que no aporten valor.

```{r, echo=FALSE}
ggplot(data = studentPor, aes(studytime)) +
  facet_wrap(~ pass) +
  geom_histogram(bins = 12, stat = "count", fill="dodgerblue1") +
  ggtitle("Distribution of Higher Education in student data") +
  xlab("Higher Education") +
  ylab("Distribution of Higher Education")+
  theme(plot.title=element_text(face="bold"))
```

## Relación amorosa

Los alumnos con relación amorosa o no, es determinante a la hora de aprobar. Como se aprecia en el plot, influye negativamente que el alumno se encuentre dentro de una relación amorosa.

```{r, echo=FALSE}
ggplot(data = studentPor, aes(romantic)) +
  facet_wrap(~ pass) +
  geom_histogram(bins = 12, stat = "count", fill="dodgerblue1") +
  ggtitle("Distribution of mjob Education in student data") +
  xlab("mjob") +
  ylab("Distribution of Higher Education")+
  theme(plot.title=element_text(face="bold"))
```

## Dirección del alumno (address)

La dirección (address) del alumno posee cierta correlación con la nota final. A primera vista, es dificil entender dar una explicación de dicha correlación aunque puede que esta influya directamente con otra variable. Por ejemplo, el hecho que viva en el campo o en la ciudad influye bastante en el tipo los estudios de sus padres.

```{r, echo=FALSE}
ggplot(data = studentPor, aes(address)) +
  facet_wrap(~ pass) +
  geom_histogram(bins = 12, stat = "count", fill="dodgerblue1") +
  ggtitle("Distribution of mjob Education in student data") +
  xlab("mjob") +
  ylab("Distribution of Higher Education")+
  theme(plot.title=element_text(face="bold"))
```


## Edad del alumno

La nota media final está por debajo de aprobado en las edades de 19 y 22. En el gráfico siguiente hay pocas observaciones a partir de las edades de 19 años por lo que la media es muy sensible a valores concretos

Media de notas finales por edad: 
```{r, echo=FALSE}
ddply(studentPor.original,~age,summarise,mean=mean(g3),median=median(g3), sum = sum(g3))
```


```{r, echo=FALSE}
ggplot(data = studentPor, aes(age)) +
  facet_wrap(~ pass) +
  geom_histogram(bins = 12, stat = "count", fill="dodgerblue1") +
  ggtitle("Distribution of age in student data") +
  xlab("Age") +
  ylab("pass")+
  theme(plot.title=element_text(face="bold"))
```

# Reglas de Asociación

Se han aplicado reglas de asociación con el objetivo de detectar asociaciones entre las diferentes variables del dataset, de forma que podamos comprender mejor dicho dataset y qué variables son mas interesantes de cara a clasificar y evaluar los estudiantes.

Las  menos correladas están son failures, school, age o walc entre otras. Estas las descartaremos en los siguientes análisis.

```{r}
transactions.studentPor <- as(studentPor.factor,"transactions")
itemFrequencyPlot(transactions.studentPor, support=0.1, cex.names=0.8)

iAdult <- apriori(transactions.studentPor, parameter = list(support = 0.1, target="frequent"))
iAdult <- sort(iAdult, by="support") # Los ordenamos por el valor del soporte
inspect(head(iAdult, n=10)) # Inspeccionamos los 10 primeros
```
```{r}
barplot(table(size(iAdult)), xlab="itemset size", ylab="count")
inspect(iAdult[size(iAdult)==1])

imaxAdult <- iAdult[is.maximal(iAdult)]
inspect(head(sort(imaxAdult, by="support")))

icloAdult <- iAdult[is.closed(iAdult)]
inspect(head(sort(icloAdult, by="support")))

barplot( c(frequent=length(iAdult), closed=length(icloAdult),
maximal=length(imaxAdult)), ylab="count", xlab="itemsets")
```

```{r}
reglas <- apriori(transactions.studentPor, parameter=list(support=0.1, confidence=0.75, minlen=2))
reglas.sorted <- sort(reglas, by="lift")
plot(reglas.sorted)
```

***** apriori aplicando estudio previo 

```{r, echo=FALSE}
aso.student <- studentPor %>% select(medu, fedu, famsup, pass, romantic, address, age, failures)
aso.student <- data.frame(sapply(aso.student, as.factor))
```

En primer lugar aplicamos el algoritmo Apriori, con un soporte minimo de 0.09 y una confianza de 0.8.

```{r, echo=FALSE}
deleteRebundantRules <- function (rules) {
  subsetMatrix <- is.subset(rules, rules)
  subsetMatrix[lower.tri(subsetMatrix, diag=TRUE)] <- FALSE
  redundant <- colSums(subsetMatrix, na.rm=TRUE) >= 1
  rules <- rules[!redundant]
  return (rules)
}

createRules <- function (dt, supp = 0.1, conf = 0.8, minlen=2, maxlen=5) {
  rules <- apriori(dt, parameter = list(supp = supp , conf = conf, minlen=minlen, maxlen=maxlen))
  
  rules <- deleteRebundantRules(rules)
  #quality(rules) <- cbind(quality(rules), interestMeasure(rules, c("support", "chiSquare", "confidence", "conviction", "cosine", "coverage", "leverage", "lift", "oddsRatio"), dt))
  
  return (rules)
}

plotRules <- function(rules) {
  plot(rules)
  plot(rules, method="graph")
  plot(rules, method="grouped")
  plot(rules, method="paracoord", reorder=TRUE)
}
```


```{r, results='hide'}
aso.student.transactions <- as(aso.student,"transactions") 
itemFrequencyPlot(aso.student.transactions, support=0.1, cex.names=0.8)
aso.student.rules <- apriori(aso.student.transactions, parameter=list(support=0.1,target="frequent"))
```

En el siguiente gráfico vemos la distribución de los tamaños de los itemsets frecuentes. Vemos cómo el tamaño más común es 2 items por itemset. También se muestran los primeros 10 itemsets frecuentes.

```{r}
barplot(table(size(aso.student.rules)), xlab="itemset size", ylab="count")
inspect(head(aso.student.rules))
```

```{r, echo=FALSE}
aso.student.rules <- createRules(aso.student, supp = 0.15,  conf = 0.8, minlen = 4)
#Ordenamos los ítems por soporte descendente
aso.student.rules <- deleteRebundantRules(aso.student.rules)
aso.student.rules.sorted <- sort(aso.student.rules, by="confidence")
inspect(aso.student.rules.sorted)
plotRules(aso.student.rules.sorted)
```

```{r, echo = TRUE}
rules.persons <- subset(aso.student.rules, subset = rhs %in% c("pass=1"))
inspect(head(rules.persons))
rules.persons <- subset(aso.student.rules, subset = rhs %in% c("failures=0"))
inspect(head(rules.persons))
```


Como podemos ver, obtenemos un conjunto de 16 reglas. Ordenadas por la medida de soporte, las 3 primeras reglas nos proporcionan gran cantidad de información, puesto que nos indican que en un 80% (soporte=0.80) de los casos de nuestro dataset la nota del alumno será aprobada en caso de que quiera estudiar estudios superiores o que un 50% de los alumnos arpobado son los que no tienen pareja sentimental o tiene soporte educacional por parte de sus padres. Finalmente un 61% de los alumnos aprobados viven el la ciudad.

Esto nos indica que, en general, segun nuestro dataset aquellos alumnos que cumplan alguna o ambas de estas reglas obtendran, probablemente, un aprobado en la notal final. Por tanto, las eliminaremos, de los posteriores analisis para evitar reglas innecesarias y que se pueden intuir a simple vista

```{r, echo=FALSE}
aso.student.rules.sorted <- sort(aso.student.rules, by="lift")
inspect(head(aso.student.rules.sorted))
```

Si ordenamos por *lift* podemos observar que existe una gran dependencia entre la educacón del padreo de la madre con aprobar o no, además de las variaable "romantic" , "higher" o "famsup" anteriormente comentado.

Si queremos acotar y seguir analizando los ítemsets frecuentes, usaremos rangos definidos por las variables **minlen** y **maxlen** para definir cuantos ítems queremos que formen los sets. Además vamos a 

```{r, echo=FALSE}
studentPor$meduBin <- ifelse(studentPor$medu < 2, 0, 1)
studentPor$feduBin <- ifelse(studentPor$fedu < 2, 0, 1)
studentPor$isAdult <- ifelse(studentPor$age < 18, 0, 1)

aso.student.2 <- studentPor %>% select(meduBin, feduBin, isAdult, famsup, pass, romantic, higher, address)
aso.student.2 <- data.frame(sapply(aso.student.2, as.factor))

aso.student.2.rules <- createRules(aso.student.2, supp = 0.4,  conf = 0.8, minlen = 3)
#Ordenamos los ítems por soporte descendente
aso.student.rules.sorted <- sort(aso.student.2.rules, by="confidence")
inspect(aso.student.rules.sorted)

```